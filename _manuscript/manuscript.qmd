---
lang: en
title: "Updated Criteria for the Diagnostic Procedure for Parkinson’s Disease Dementia on Level I and their Validity in Deep Brain Stimulation Cohort"
shorttitle: "Parkinson's Disease Dementia Level I Criteria"
author:
  - name: Martina Mana
    corresponding: false
    orcid: "0009-0007-4665-3946"
    role:
      - Conceptualization
      - Data curation
      - Writing - original draft
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Josef Mana
    corresponding: false
    orcid: "0000-0002-7817-3978" 
    email: "josef.mana@lf1.cuni.cz"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Formal analysis
      - Software
      - Methodology
      - Project administration
      - Validation
      - Writing - original draft
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tereza Uhrova
    corresponding: false
    email: "tereza.uhrova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Robert Jech
    corresponding: false
    orcid: "0000-0002-9732-8947"
    email: "jech@cesnet.cz"
    role:
      - Funding acquisition
      - Resources
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Ondrej Bezdicek
    corresponding: true
    orcid: "0000-0002-5108-0181"
    email: "ondrej.bezdicek@gmail.com"
    role:
      - Investigation
      - Data curation
      - Funding acquisition
      - Conceptualization
      - Project administration
      - Supervision
      - Writing - original draft
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
abstract: ""
keywords:
  - Parkinson’s disease
  - Parkinson's disease dementia
  - level I criteria
format:
 apaquarto-pdf:
   documentmode: man
   a4paper: true
   pdf-engine: lualatex
   floatsintext: false
   keep-tex: false
bibliography: references.bib
floatsintext: false
numbered-lines: false
suppress-title-page: false
warning: false
echo: false
---

```{r}
#| label: "import"

library(targets)
library(tidyverse)

upstore <- here::here(tar_config_get("store"))
tar_source(here::here("R"))
data <- tar_read(raw_data, store = upstore)
crit <- tar_read(pdd_data, store = upstore)$criteria

```

# Introduction

Parkinson’s disease (PD) is a neurodegenerative disorder characterized by a gradual and progressive onset of motor symptoms, including rigidity, bradykinesia, and resting tremors, which eventually extend to both motor and non-motor impairments [@postuma2015]. Beyond these hallmark features, cognitive decline is a critical aspect of the disease trajectory, culminating in Parkinson’s disease dementia (PDD) in a substantial subset of patients [@meireles2012].

The diagnostic criteria for PDD [@dubois2007], first formalized in 2006, were heavily influenced by frameworks established for Alzheimer’s disease (AD) owing to the absence of PD-specific biomarkers that could facilitate a biologically grounded diagnostic system. Although these criteria provided a valuable initial foundation, they lacked the specificity required to capture the distinct pathophysiological and cognitive features of PD-related dementia [@emre2007; @yamashita2023].

An important feature of the original criteria was the provision of an algorithm that allowed for flexibility in test selection [@dubois2007]. Specifically, clinicians could choose between months reversed or seven backwards for attention assessment, lexical fluency or clock drawing for executive function evaluation, MMSE pentagons for visuospatial ability, and three-word recall for memory assessment. The availability of multiple operationalization options for PDD enhances the ability to examine the psychometric properties of the construct. Agreement across different criteria allows for the parallel computation of inter-rater reliability , which, in turn, facilitates the calculation of construct validity [@conway1995] further strengthening the diagnostic framework for PDD.

Subsequent advancements have introduced the concept of Parkinson’s disease mild cognitive impairment (PD-MCI), refining the understanding of cognitive dysfunction in PD [@litvan2012]. The PD-MCI criteria, published in 2012, have propelled progress in diverse areas, enabling improvements in clinical characterization, identification of genetic correlates, therapeutic interventions, clinical trial design, and the assessment of progression risk to PDD [@hoogland2017; @hoogland2019; @aarsland2021].

Currently, efforts are focused on refining the PDD diagnostic framework to improve its consistency and applicability in both research and clinical contexts across multiple centers [@kulisevsky2024]. Our prior investigations have underscored the importance of employing rigorous psychometric methodologies to differentiate PD-MCI from PDD, particularly given that a diagnosis of PDD remains a contraindication for deep brain stimulation (DBS) [@bezdicek2016; @deuschl2006].

The present study evaluates the diagnostic concordance between the original Level I PDD criteria, as established by the Movement Disorder Society (MDS) Task Force [@emre2007; @dubois2007] and criteria inspired by the recent call for change [@kulisevsky2024] within a PD cohort selected for DBS. Furthermore, both sets of criteria are compared to PDD diagnosed on Level II. The study aims to address following research objectives (RO): 1) to estimate the prevalence of PDD among patients considered for DBS (RO1), 2) to assess variability in PDD diagnosis depending on the diagnostic criteria applied (RO2), 3) to evaluate the diagnostic concordance between different sets of PDD criteria (RO3), and 4) to identify diagnostic components that contribute to variability in PDD classification across criteria (RO4). By addressing these objectives, this study seeks to validate the revised PDD criteria and evaluate their relevance in the context of DBS eligibility, thereby contributing to the refinement of cognitive assessment protocols in PD.

# Methods

## Participants

```{r}
#| label: "dates"

continue <- all(!is.na(data$assdate))
stopifnot("Some assessment dates are missing" = continue)

dates <-
  sapply(
    c("min", "max"),
    function(f) {
      date <- do.call(f, list(data$assdate))
      paste(month(date, label = T, abbr = F), year(date))
    }
  )
```

This study retrospectively analyzed clinical data from a cohort of patients with PD considered for treatment via DBS of subthalamic nucleus at the General University Hospital in Prague. All patients were diagnosed with idiopathic PD by a movement disorder specialist according to the MDS Clinical Diagnostic Criteria for PD [@postuma2015]. Clinical records spanning `r dates["min"]` to `r dates["max"]` were examined. All participants underwent neuropsychological evaluation conducted by a trained clinical psychologist as part of standard preoperative cognitive assessments for DBS eligibility at the General University Hospital in Prague.

Ethical approval for the study protocol was obtained from the Ethics Committee of the General University Hospital in Prague. Informed consent was secured from all patients prior to their neuropsychological assessments, in adherence to ethical research guidelines.

## Neuropsychological Assessment

Cognitive performance was evaluated at both Level I (abbreviated assessment) and Level II (comprehensive assessment) according to the standard MDS neuropsychology battery for Parkinson's Disease Mild Cognitive Impairment (PD-MCI) [@litvan2012, @bezdicek2017]. Level I was assessed using the Mini-Mental State Examination (MMSE) [@stepankova2014; @folstein1975] and the Montreal Cognitive Assessment (MoCA) [@kopecek2016; @nasreddine2005], both of which provide measures of global cognitive functioning. The neuropsychological assessment at Level II covered five cognitive domains, each evaluated through specific tests as follows: attention and working memory assessed using Trail Making Test Part A (TMT-A) [@bezdicek2012; @reitan2004], WAIS Digit Span Backward (WAIS DSB) [@wechsler1997]; executive function evaluated via Categorical Verbal Fluency (CF) [@benton1989], subtest from the Prague Stroop Test – Colors (PST-C) [@bezdicek2021]; language measured with the WAIS Similarities subtest [@wechsler1997] and the Boston Naming Test (BNT-60) [@kaplan1983]; memory examined using the Rey Auditory Verbal Learning Test (RAVLT) [@frydrychova2018; @rey1964] for delayed recall, the Brief Visual Memory Test–Revised (BVMTR) [@havlík2020; @benedict1997] for delayed recall, and WAIS Family Pictures subtest [@wechsler1997] including delayed recall and forced choice recognition; visuospatial function assessed through the Judgment of Line Orientation Test (JoLO) [@benton1983], and Clock Drawing Test (CLOX) [@royall1998].

In addition to the core cognitive assessments, tasks such as the Clock Drawing Test (CDT) and Letter Fluency tasks were included to capture domain-specific impairments. The classification of Parkinson’s Disease Dementia (PDD) based on Level I criteria was determined using established scoring thresholds from Dubois et al. [@dubois2007] with corresponding MoCA equivalents.

To assess functional impairment, the Functional Activities Questionnaire (FAQ)[@bezdicek2011; @pfeffer1982] was administered. Additionally, neuropsychiatric status was evaluated using the Beck Depression Inventory-II (BDI) [@ciharova2020; @beck1996] and State-Trait Anxiety Inventory (STAI) [@spielberg1983; @mullner1980]. Psychotic symptoms were assessed through structured psychiatric interviews conducted by a trained psychiatrist.

## Theoretical and Empirical Estimands

Following the framework proposed by Lundberg et al. (2021), this section connects our research objectives and their corresponding theoretical (i.e., targets of inference) and empirical (i.e., data-driven) estimands. The theoretical estimand refers to a unit-specific quantity defined over a target population and represents the ideal quantity that would address the research question under optimal conditions—such as access to complete population data or perfect experimental control. In contrast, the empirical estimand corresponds to the quantity that is actually computable using the available dataset, given real-world constraints. In our study, the target population for all theoretical estimands is defined as individuals diagnosed with Parkinson’s disease (PD) who are potential candidates for deep brain stimulation (DBS) treatment.

The theoretical estimand corresponding to the RO1 is the true prevalence of probable PDD in this population. Empirically, this is estimated by calculating the proportion of patients classified as having probable PDD according to each of the diagnostic criteria under consideration.

For the RO2, the theoretical estimand is the variance in prevalence attributable to the diagnostic process itself—that is, the extent to which different sets of criteria yield differing prevalence estimates for the same population. This variability is empirically quantified by comparing the distribution of PDD classifications across criteria within the cohort.

The RO3 concerns diagnostic concordance. Here, the theoretical estimand is a set of population-level contingency tables comparing PDD classifications assigned by each pair of diagnostic criteria, along with derived metrics such as sensitivity, specificity, and kappa coefficients. The corresponding empirical estimands are represented by matrices generated through pairwise Receiver Operating Characteristic (ROC) curve analyses that evaluate the discriminatory performance of each diagnostic set.

Finally, for the RO4, the theoretical estimand is defined as the set of diagnostic components whose variation systematically alters the probability of a probable PDD diagnosis. This aspect of the study is exploratory in nature. Empirically, we assess the contribution of each diagnostic feature by examining how variations in operational definitions (e.g., domain-specific thresholds, criteria for functional impairment) influence the empirical estimands derived for the first three objectives. This allows us to identify the diagnostic elements most responsible for inter-criterion discrepancies. We approach this RO from an exploratory point of view and evaluate the importance of each PDD criteria component by observing change in empirical estimands for RO1-3 when stratified by different oprationalization decisions.

## Operationalization of Parkinson's Disease Dementia

In this study, we applied three distinct sets of diagnostic criteria for **probable**[^1] PDD at Level I. The first set was based on the original framework [@dubois2007], which utilized the Mini-Mental State Examination (MMSE) as a global cognitive screening tool, supplemented by assessments of attention, executive function, visuospatial abilities, and memory. The second set of criteria was drawn from the recent call for change of dementia diagnostic guidelines [@kulisevsky2024], which advocate for more sensitive cognitive domain assessments in the context of Parkinson's disease (PD). This updated approach incorporated specific items from the Montreal Cognitive Assessment (MoCA) to better detect PD-related dementia. The third approach applied the Czech version of the shortened Montreal Cognitive Assessment (sMoCA) [@bezdicek2020], a time-efficient modification designed to ascertain whether equivalent cognitive impairments could be reliably identified using a reduced testing protocol. Lastly, the fourth approach followed the Level II battery protocol, which is commonly used in the evaluation of PD-MCI. **The Level II methodology, including the use of a regression-based normative scoring approach, has been detailed in a prior study [@bezdicek2017]. Refer to @tbl-criteria**[^2] to a summary of the components and scoring thresholds of each diagnostic criterion. All non-cognitive criteria of probable PDD (i.e., diagnosis of PD that developed before dementia and absence of Major Depression, delirium or other abnormalities that obscure diagnosis were established by an independent neurological and psychiatric assessments and held true for all patients in the sample).

<<<<<<< HEAD
[^1]: **JM: We should unite the terminlogy. Most importantly, I reckon, we should differentiate between "probable PDD" (what is implied by meeting all the criteria within an operationalization) and "PDD" (the latent state of patient's cognition); and to use consistently the following trifecta - "criterion," "operationalization" and their "component".**
=======
[^3]: **JM: We should unite the terminology. Most importantly, I reckon, we should differentiate between "probable PDD" (what is implied by meeting all the criteria within an operationalization) and "PDD" (the latent state of patient's cognition); and to use consistently the following trifecta - "criterion," "operationalization" and their "component".**
>>>>>>> 0d33cc0b0961c3776e2225e6d367cfc52b9a2e48

[^2]: **JM: Placeholder until we make the table proper.**

```{r}
#| label: "tbl-criteria"

gt::gt(crit)
```

\[Insert Table 1 here\]

```{r}
#| label: "criteria-check"

critnum <-
  sapply(
    c("mmse", "moca", "smoca", "lvlII"),
    function(i)
      subset(crit, group == i) |>
      nrow()
  )

continue <- !any(critnum == 0)
#stopifnot("Some criteria are missing" = continue)
```

For each of these diagnostic approaches, we applied two operationalization strategies based on deficits in Instrumental Activities of Daily Living (IADL). First, we utilized FAQ item 9, which approximates the pill questionnaire from the original criteria [@dubois2007] employing a cut-off score of 2 points or higher. Second, we applied the entire Functional Activities Questionnaire (FAQ) as suggested in the call for change [@kulisevsky2024], employing a cut-off score of 7 points or higher based on Czech normative data [@bezdicek2011]. These methodologies resulted in a total of `r sum(critnum)` operationalizations, which were distributed across different diagnostic criteria: `r critnum["mmse"]` MMSE-based, `r critnum["moca"]` MoCA-based, `r critnum["smoca"]` sMoCA-based, and `r critnum["lvlII"]` based on the Level II battery[^3].

[^3]: **JM: Need to add Level II operationalization and allow the `stopifnot()` test code above. My job.**

## Statistical Analyses

For sample description, we summarized continuous variables using mean, standard deviation, median, minimum, and maximum values. Categorical variables were summarized by the number of patients in each category. To address study objectives, we started by repeatedly assigning each patient the diagnosis of probable PDD based on each PDD operationalization listed in @tbl-criteria resulting in a `r sum(data$incl)` (patients) $\times$ `r sum(critnum)` (operationalizations) matrix where each cell indicates whether a patient (row) meets criteria for probable PDD according to an operationalization (column). PDD prevalence estimates were then computed as $\frac{N_{PDD}}{N_{total}}$ separately for each operationalization to address RO1.

To address RO2-4, a set of two class cross-tabulations with associated statistics was computed for each pair of operationalizations via the `confusionMatrix()` function from the R package *caret* [@kuhn2008]. For each pair of operationalizations, the analysis was repeated twice such that each variables of the pair served once as the reference and once as the predictor. Following measures were used to evaluate pairwise concordance between different operationalizations of PDD criteria: 1) Cohen's $\kappa$ with its 95% confidence interval (CI) computed via the `cohen.kappa()` function from the R package *psych* [@revelle2024]; 2) Accuracy (i.e., the proportion of correct predictions, both true positives and true negatives, among the total number of cases) with its 95% CI; 3) Sensitivity/Recall (i.e., the proportion of true positives); and 4) Specificity (i.e., the proportion of true negatives).[^4]

[^4]: Unlike Cohen's $\kappa$, Accuracy, Sensitivity and Specificity are not symmetrical, i.e., their value depend on which variable is considered reference and which is considered predictor. Consequently, we report these values twice for each pair of operationalizations. Note that the Sensitivity of a reference/predictor pair corresponds to the Positive Predictive Value if their roles were reversed. The same relationship holds true between the Specificity and the Negative Predictive Value.

Finally, the No Information Rate (NIR) was calculated for each pair of operationalizations. NIR is the accuracy that could be obtained by always predicting the majority class and in our case it is equivalent to the complement of the PDD prevalence estimate according to the reference operationalization. Accuracy of prediction was subsequently compared to the NIR via a one-sided Exact Binomial Test as implemented by the `binom.test()` R stats function. Reference/predictor pairs associated with p \< .05 were considered to show significantly better accuracy than NIR. In other word, for reference/predictor pairs associated with p \< .05, we conclude that knowing the probable PDD status according to the predictor operationalization helps to estimate the probable PDD status according to the reference operationalization and the two opeartionalizations thus show substantial concordance.

Data wrangling and visualizations were done in the *tidyverse* package [@wickham2019] and tables were formatted in the *gt* package [@iannone2024]. All analyses were conducted with the R (version `r with(version, paste(major, minor, sep="."))`) software environment for statistical computing [@rsoft]. The software code supporting this article is available at <https://github.com/josefmana/DemCr1t.git>.[^5]

[^5]: **JM: Do not forget to make it public before submitted!**

# Results

```{r}
#| label: "results"

desc <- tar_read(sample_description    , store = upstore)
prev <- tar_read(prevalence_summaries  , store = upstore)
conc <- tar_read(concordance_statistics, store = upstore)
perc <- prev$table$perc
```

## Sample Description

A total of `r sum(data$incl)` patients were included. Demographic and clinical characteristics of the sample are summarized in @tbl-desc. **...**[^6]

[^6]: **JM: Give some brief impressions from the Table 2 here. E.g., evaluate sex proportion, age, (we are missing education for some reason) etc. with general PD population (e.g., from some meta-analysis). Maybe say a word or two about mean cognitive profile or its spread.**

\[Insert Table 2 here\]

```{r}
#| label: "tbl-desc"

desc$gtable
```

## Prevalence Estimates

Operationalization-wise prevalence estimates are presented in @tbl-prev. On average, estimated prevalence was `r do_summary(perc, 2, "M")`% (SD = `r do_summary(perc, 2, "SD")`, Md = `r do_summary(perc, 2, "Md")`, range `r do_summary(perc, 2, "minmax")`). Notably, the prevalence estimate was substantially lower when FAQ item 9 was used as a criterion of IADL deficit (M = `r do_summary(perc[grepl("FAQ 9", prev$table$IADL)], 2, "M")`%, SD = `r do_summary(perc[grepl("FAQ 9", prev$table$IADL)], 2, "SD")`, range `r do_summary(perc[grepl("FAQ 9", prev$table$IADL)], 2, "minmax")`) compared to using total FAQ score criterion (M = `r do_summary(perc[!grepl("FAQ 9", prev$table$IADL)], 2, "M")`%, SD = `r do_summary(perc[!grepl("FAQ 9", prev$table$IADL)], 2, "SD")`, range `r do_summary(perc[!grepl("FAQ 9", prev$table$IADL)], 2, "minmax")`) as demonstrated also in @fig-prev.[^7]

[^7]: **JM: For oneself - work on the code here, it ain't good.**

\[Insert Table 3 and Figure 1[^8] here\]

[^8]: **JM: For thyself - add description.**

```{r}
#| label: "tbl-prev"

prev$gtable
```

```{r}
#| label: "fig-prev"

prev$plot
```

## Criteria Concordance

Results of the analyses of prediction Accuracy, Cohen's $\kappa$, Sensitivity and Specificity are presented in @fig-acc, @fig-kappa, @fig-sens and @fig-spec respectively. Numerical results are available ... [^9]

[^9]: **JM: ... as some kind of Supplementary Table, ideally html but Excel file would work as well.**

**In this section, we need to discuss among ourselves what and how to report such that the results give enough information, the most important information and are readable as well.**

\[Insert Figure 2[^10] here\]

[^10]: **JM: For thyself - add description.**

```{r}
#| label: "fig-acc"

conc$plots$Accuracy
```

# Discussion

This study evaluated the applicability and validity of diagnostic frameworks for diagnosing probable PDD within a cohort of patients considered for deep brain stimulation (DBS). Our results demonstrate that diagnostic outcomes are markedly influenced by the chosen type of operationalization, particularly in relation to the assessment of the cognitive domains and IADLs.

## Variability in Prevalence Estimates

One of the key findings of this study was the broad range of estimated PDD prevalence depending on the operationalization strategy. As seen in Table 3, prevalence estimates varied from 2.00% to 16.75%, with the highest being derived from a combination of the sMoCA and the total FAQ score criterion. When only FAQ item 9 was used to determine IADL deficits, the prevalence estimates were significantly lower (M = 3.09%, SD = 0.48), underscoring significant influence of functional assessment choice on diagnostic outcomes.

## Cognitive and Clinical Context

The relatively low prevalence of PDD across operationalizations may also reflect the relatively preserved cognitive profile of the DBS cohort, as evident in Table 2. The mean MoCA (M = 24.07, SD = 3.48) and MMSE (M = 26.69, SD = 2.22) scores suggest that the majority of patients were functioning at a globally intact level. This likely reflects the pre-selection of cognitively preserved individuals for DBS, in line with standard eligibility criteria [@bronstein2011].

Additionally,  memory performance metrics, such as RAVLT delayed recall (M = 7.16/15), and BVMTR delayed recall (M = 7.89/12), also possibly indicate generally mild impairments in the domain crucial for distinguishing PD-MCI from PDD. This aligns with previous literature suggesting that Level I criteria may overestimate dementia prevalence in populations with only subtle deficits if not carefully calibrated [@aarsland2021; @bezdicek2016].

## Implications for DBS Eligibility and Clinical Practice

Our findings also bear direct implications for clinical decision-making, especially in the context of surgical candidacy for DBS. Given that PDD remains a contraindication for DBS, the observed diagnostic instability could result in disparate treatment decisions based solely on which cognitive criteria are employed. Thus, harmonization of assessment procedures and operational cutoffs is essential to ensure equitable access to surgical treatment while maintaining diagnostic rigor.

Moreover, the relatively high variability in diagnostic outputs calls for the incorporation of multidimensional tools, such as comprehensive neuropsychological batteries (Level II) or standardized regression-based normative approaches, as confirmatory steps in ambiguous cases. Such practices may mitigate false positives and enhance the robustness of Level I screening.

## Constraints on generalizability

This study is limited by its retrospective nature and the homogenous DBS candidate cohort, which may reduce generalizability to more or less cognitively impaired PD populations. Moreover, the use of a Czech-specific normative framework may limit cross-cultural applicability, though it reflects the clinical reality of local practices [@simons2017].

## Future Directions

Future research should focus on prospective validation of updated Level I criteria against longitudinal functional outcomes and neurobiological markers. Additionally, the development of adaptive diagnostic algorithms that can integrate performance across cognitive, functional, and psychiatric domains may enhance diagnostic sensitivity while reducing the risk of over-classification.

# Conclusions

This study systematically evaluated various Level I diagnostic criteria for PDD and the operationalizations in a DBS candidate cohort. Our findings underscore the significant variability in PDD prevalence estimates depending on both the selected cognitive tests and the thresholds applied to define functional impairment. The divergence observed across operationalizations demonstrates the sensitivity of diagnostic outcomes to seemingly minor methodological choices.

While the call for a change [@kulisevsky2024] criteria offer enhanced sensitivity by leveraging MoCA-based components and broader IADL assessments, the use must be cautiously calibrated to prevent over-diagnosis in populations with mild or borderline cognitive deficits. Conversely, overly conservative criteria, such as reliance on pill questionnaire (i.e. FAQ item 9 equivalence) may fail to detect meaningful functional decline and thus under-identify true cases of probable PDD.

Ultimately, this study contributes to the improving landscape of PDD diagnostics by offering empirical evidence for the refinement of Level I criteria and reinforcing the value of psychometric rigor in clinical neuropsychology. Future work should extend this validation to longitudinal trajectories and integrate neurobiological correlates, ensuring that cognitive criteria remain both scientifically grounded and clinically actionable.

# References

# Appendix

```{r}
#| label: "fig-kappa"

conc$plots$Kappa
```

```{r}
#| label: "fig-sens"

conc$plots$Sensitivity
```

```{r}
#| label: "fig-spec"

conc$plots$Specificity
```
